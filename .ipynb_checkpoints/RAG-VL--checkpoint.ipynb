{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d8a968-5838-4d78-9527-b9b1c7dbd682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r \"C:\\Users\\ilang\\Downloads\\requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6022171-8ebc-4a7a-8537-e9cbd451d693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.8.0+cpu)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.23.0+cpu)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.8.0+cpu)\n",
      "Requirement already satisfied: filelock in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (74.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ilang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ilang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ilang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21b66b1c-bcb7-4ed5-babe-9b77e5169f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ftfy in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (6.3.1)\n",
      "Requirement already satisfied: regex in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ftfy) (0.2.13)\n",
      "Requirement already satisfied: colorama in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ilang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ilang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ilang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip install ftfy regex tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2666765c-4438-4464-acdb-9eb292a82c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"git --version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc64a13-08eb-4818-ab10-20f619e56c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to c:\\users\\ilang\\appdata\\local\\temp\\pip-req-build-xav1ktkm\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: ftfy in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from clip==1.0) (6.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from clip==1.0) (24.1)\n",
      "Requirement already satisfied: regex in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from clip==1.0) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from clip==1.0) (4.66.5)\n",
      "Requirement already satisfied: torch in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from clip==1.0) (2.8.0+cpu)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from clip==1.0) (0.23.0+cpu)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Requirement already satisfied: filelock in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->clip==1.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->clip==1.0) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->clip==1.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->clip==1.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->clip==1.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->clip==1.0) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->clip==1.0) (74.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision->clip==1.0) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision->clip==1.0) (10.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->clip==1.0) (0.4.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch->clip==1.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->clip==1.0) (2.1.5)\n",
      "Building wheels for collected packages: clip\n",
      "  Building wheel for clip (pyproject.toml): started\n",
      "  Building wheel for clip (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369633 sha256=6d6658920366614409475f3c063b5383a7eda4289eb88b0ecfd5b0b1f8aa3ef7\n",
      "  Stored in directory: C:\\Users\\ilang\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-vsqdj3xu\\wheels\\35\\3e\\df\\3d24cbfb3b6a06f17a2bfd7d1138900d4365d9028aa8f6e92f\n",
      "Successfully built clip\n",
      "Installing collected packages: clip\n",
      "Successfully installed clip-1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ilang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git 'C:\\Users\\ilang\\AppData\\Local\\Temp\\pip-req-build-xav1ktkm'\n",
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ilang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ilang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0899459d-de1f-4c82-9649-6981fcb57a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.9.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from faiss-cpu) (24.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ilang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ilang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ilang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf88efa4-cb85-4d35-826f-178cec4fd461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import tabula\n",
    "import faiss\n",
    "import json\n",
    "import base64\n",
    "import pymupdf\n",
    "import requests\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from botocore.exceptions import ClientError\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a37f6afb-fa8b-4ef2-b623-a5e8664a9dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully: data\\attention_paper.pdf\n",
      "data\\attention_paper.pdf\n"
     ]
    }
   ],
   "source": [
    "# Downloading the dataset - URL of the \"Attention Is All You Need\" paper (Replace it with the URL of the PDF file/dataset you want to download)\n",
    "url = \"https://arxiv.org/pdf/1706.03762.pdf\"\n",
    "\n",
    "# Set the filename and filepath\n",
    "filename = \"attention_paper.pdf\"\n",
    "filepath = os.path.join(\"data\", filename)\n",
    "\n",
    "# Create the data directory if it doesn't exist\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(filepath, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"File downloaded successfully: {filepath}\")\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "print(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0677180-f219-4ef7-bd82-3e55650bb298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"..\\data\\attention_paper.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1f0f97d5e50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the PDF file\n",
    "import os\n",
    "from IPython.display import IFrame\n",
    "filepath = \"..\\\\data\\\\attention_paper.pdf\"\n",
    "display.IFrame(filepath, width=1000, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfc84014-5a9a-45bf-820c-c676a957fb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilang\\data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bbf4f34-1087-4073-86df-cd2af500d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directories\n",
    "def create_directories(base_dir):\n",
    "    directories = [\"images\", \"text\", \"tables\", \"page_images\"]\n",
    "    for dir in directories:\n",
    "        os.makedirs(os.path.join(base_dir, dir), exist_ok=True)\n",
    "\n",
    "# Process tables\n",
    "def process_tables(doc, page_num, base_dir, items):\n",
    "    try:\n",
    "        tables = tabula.read_pdf(filepath, pages=page_num + 1, multiple_tables=True)\n",
    "        if not tables:\n",
    "            return\n",
    "        for table_idx, table in enumerate(tables):\n",
    "            table_text = \"\\n\".join([\" | \".join(map(str, row)) for row in table.values])\n",
    "            table_file_name = f\"{base_dir}/tables/{os.path.basename(filepath)}_table_{page_num}_{table_idx}.txt\"\n",
    "            with open(table_file_name, 'w') as f:\n",
    "                f.write(table_text)\n",
    "            items.append({\"page\": page_num, \"type\": \"table\", \"text\": table_text, \"path\": table_file_name})\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting tables from page {page_num}: {str(e)}\")\n",
    "\n",
    "# Process text chunks\n",
    "def process_text_chunks(text, text_splitter, page_num, base_dir, items):\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        text_file_name = f\"{base_dir}/text/{os.path.basename(filepath)}_text_{page_num}_{i}.txt\"\n",
    "        with open(text_file_name, 'w', encoding='utf-8') as f:\n",
    "            f.write(chunk)\n",
    "        items.append({\"page\": page_num, \"type\": \"text\", \"text\": chunk, \"path\": text_file_name})\n",
    "\n",
    "# Process images\n",
    "def process_images(page, page_num, base_dir, items):\n",
    "    images = page.get_images()\n",
    "    for idx, image in enumerate(images):\n",
    "        xref = image[0]\n",
    "        pix = pymupdf.Pixmap(doc, xref)\n",
    "        image_name = f\"{base_dir}/images/{os.path.basename(filepath)}_image_{page_num}_{idx}_{xref}.png\"\n",
    "        pix.save(image_name)\n",
    "        with open(image_name, 'rb') as f:\n",
    "            encoded_image = base64.b64encode(f.read()).decode('utf8')\n",
    "        items.append({\"page\": page_num, \"type\": \"image\", \"path\": image_name, \"image\": encoded_image})\n",
    "\n",
    "# Process page images\n",
    "def process_page_images(page, page_num, base_dir, items):\n",
    "    pix = page.get_pixmap()\n",
    "    page_path = os.path.join(base_dir, f\"page_images/page_{page_num:03d}.png\")\n",
    "    pix.save(page_path)\n",
    "    with open(page_path, 'rb') as f:\n",
    "        page_image = base64.b64encode(f.read()).decode('utf8')\n",
    "    items.append({\"page\": page_num, \"type\": \"page\", \"path\": page_path, \"image\": page_image})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31fad315-4cff-4030-a498-37783d08a934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDF pages:   0%|                                                                                  | 0/15 [00:00<?, ?it/s]Failed to import jpype dependencies. Fallback to subprocess.\n",
      "No module named 'jpype'\n",
      "Processing PDF pages:  20%|██████████████▊                                                           | 3/15 [00:04<00:20,  1.69s/it]Got stderr: Sept 24, 2025 9:01:15 PM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
      "WARNING: No Unicode mapping for summationtext (80) in font THPNLT+CMEX9\n",
      "\n",
      "Processing PDF pages:  40%|█████████████████████████████▌                                            | 6/15 [00:08<00:12,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting tables from page 5: 'utf-8' codec can't decode byte 0xb7 in position 1027: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDF pages:  53%|███████████████████████████████████████▍                                  | 8/15 [00:11<00:09,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting tables from page 7: 'utf-8' codec can't decode byte 0xb7 in position 1440: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDF pages:  60%|████████████████████████████████████████████▍                             | 9/15 [00:12<00:07,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting tables from page 8: 'utf-8' codec can't decode byte 0xd7 in position 2962: invalid continuation byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDF pages: 100%|█████████████████████████████████████████████████████████████████████████| 15/15 [00:22<00:00,  1.53s/it]\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from tqdm import tqdm\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "doc = pymupdf.open(filepath)\n",
    "num_pages = len(doc)\n",
    "base_dir = \"data\"\n",
    "\n",
    "# Creating the directories\n",
    "create_directories(base_dir)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=200, length_function=len)\n",
    "items = []\n",
    "\n",
    "# Process each page of the PDF\n",
    "for page_num in tqdm(range(num_pages), desc=\"Processing PDF pages\"):\n",
    "    page = doc[page_num]\n",
    "    text = page.get_text()\n",
    "    process_tables(doc, page_num, base_dir, items)\n",
    "    process_text_chunks(text, text_splitter, page_num, base_dir, items)\n",
    "    process_images(page, page_num, base_dir, items)\n",
    "    process_page_images(page, page_num, base_dir, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4994c14c-2fd7-4495-b7ee-39bc1513d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d64b999f-1d60-4374-bd51-e007956dc734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page': 0,\n",
       " 'type': 'text',\n",
       " 'text': 'Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or',\n",
       " 'path': 'data/text/attention_paper.pdf_text_0_0.txt'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in items if i['type'] == 'text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adb5b3fa-1090-4f45-8a6f-70cd5cc56cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page': 9,\n",
       " 'type': 'table',\n",
       " 'text': 'Vinyals & Kaiser el al. (2014) [37] | WSJ only, discriminative | 88.3\\nPetrov et al. (2006) [29] | WSJ only, discriminative | 90.4\\nZhu et al. (2013) [40] | WSJ only, discriminative | 90.4\\nDyer et al. (2016) [8] | WSJ only, discriminative | 91.7\\nTransformer (4 layers) | WSJ only, discriminative | 91.3\\nZhu et al. (2013) [40] | semi-supervised | 91.3\\nHuang & Harper (2009) [14] | semi-supervised | 91.3\\nMcClosky et al. (2006) [26] | semi-supervised | 92.1\\nVinyals & Kaiser el al. (2014) [37] | semi-supervised | 92.1\\nTransformer (4 layers) | semi-supervised | 92.7\\nLuong et al. (2015) [23] | multi-task | 93.0\\nDyer et al. (2016) [8] | generative | 93.3',\n",
       " 'path': 'data/tables/attention_paper.pdf_table_9_0.txt'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in items if i['type'] == 'table'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6ed7b29-7b19-4e74-9967-b736308abf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "import torch\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the CLIP model\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "print(\"CLIP model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ce89ef8-1dc6-4d0e-a2d1-56db6d7f7adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity scores between the image and text queries:\n",
      "a golden retriever: 0.3222\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Load the model and preprocessing pipeline\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Define inputs\n",
    "text_inputs = [\"a golden retriever\"]\n",
    "image_path = \"dog2.jpg\"\n",
    "\n",
    "# Preprocess the text\n",
    "text_tokens = clip.tokenize(text_inputs).to(device)\n",
    "\n",
    "# Preprocess the image\n",
    "image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "\n",
    "# Generate embeddings\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text_tokens)\n",
    "\n",
    "# Normalize embeddings\n",
    "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "# Compute similarity scores\n",
    "similarity = (image_features @ text_features.T).cpu().numpy()\n",
    "\n",
    "print(\"Similarity scores between the image and text queries:\")\n",
    "for i, text in enumerate(text_inputs):\n",
    "    print(f\"{text}: {similarity[0][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12ef0eb6-16a1-41bd-9fe3-14d2e0cfa224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 nearest neighbors: [[13262 17620 36245 39869 60409]]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Create a random dataset of 100,000 vectors (128 dimensions)\n",
    "d = 128  # Dimension of vectors\n",
    "nb = 100000  # Number of vectors\n",
    "np.random.seed(1234)\n",
    "data = np.random.random((nb, d)).astype('float32')\n",
    "\n",
    "# Build a FAISS index (Flat index for exact search)\n",
    "index = faiss.IndexFlatL2(d)  # L2 distance\n",
    "index.add(data)  # Add vectors to the index\n",
    "\n",
    "# Query the index\n",
    "query = np.random.random((1, d)).astype('float32')  # Single query vector\n",
    "k = 5  # Number of nearest neighbors to retrieve\n",
    "distances, indices = index.search(query, k)\n",
    "\n",
    "print(f\"Top {k} nearest neighbors: {indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18d77724-b744-486b-9ee0-9b71d2d998ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nearest_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m[indices[\u001b[38;5;241m0\u001b[39m]] \n\u001b[0;32m      2\u001b[0m nearest_vectors\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "nearest_vectors = data[indices[0]] \n",
    "nearest_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46762044-8901-43af-8532-7172fa26155e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.56.1-py3-none-any.whl.metadata (42 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.8.0+cpu)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.23.0+cpu)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.34.5-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (74.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ilang\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.56.1-py3-none-any.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.6 MB 1.0 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.0/11.6 MB 1.6 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.8/11.6 MB 2.1 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.1/11.6 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.8/11.6 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.6/11.6 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.6/11.6 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.7/11.6 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.3/11.6 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 5.3 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.34.5-py3-none-any.whl (562 kB)\n",
      "   ---------------------------------------- 0.0/562.2 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 524.3/562.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 562.2/562.2 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Downloading tokenizers-0.22.0-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 26.0 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.34.5 safetensors-0.6.2 tokenizers-0.22.0 transformers-4.56.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ilang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ilang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\ilang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip install transformers torch torchvision Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77004cae-b4d7-4873-b383-0397cba9de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "\n",
    "def generate_multimodal_embeddings(prompt=None, image_path=None, output_embedding_length=384):\n",
    "    \"\"\"\n",
    "    Generate multimodal embeddings using OpenAI's CLIP model.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The text prompt to encode.\n",
    "        image_path (str): The path to the image file to encode.\n",
    "        output_embedding_length (int): The desired dimension of output embeddings.\n",
    "    Returns:\n",
    "        dict: A dictionary containing text and/or image embeddings.\n",
    "    \"\"\"\n",
    "    if not prompt and not image_path:\n",
    "        raise ValueError(\"Please provide either a text prompt, an image path, or both as input\")\n",
    "    \n",
    "    # Load the CLIP model and processor\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "    # Initialize inputs\n",
    "    inputs = {}\n",
    "\n",
    "    if prompt:\n",
    "        inputs[\"text\"] = prompt\n",
    "\n",
    "    if image_path:\n",
    "        # Open and process the image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        inputs[\"images\"] = image\n",
    "\n",
    "    # Process inputs for the model\n",
    "    inputs = processor(**inputs, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    # Initialize embedding variables\n",
    "    text_embeddings = None\n",
    "    image_embeddings = None\n",
    "\n",
    "    # Generate embeddings\n",
    "    with torch.no_grad():\n",
    "        if \"text\" in inputs:\n",
    "            outputs = model.get_text_features(input_ids=inputs[\"input_ids\"])\n",
    "            text_embeddings = outputs / outputs.norm(dim=-1, keepdim=True)  # Normalize embeddings\n",
    "\n",
    "        if \"images\" in inputs:\n",
    "            image_outputs = model.get_image_features(pixel_values=inputs[\"pixel_values\"])\n",
    "            image_embeddings = image_outputs / image_outputs.norm(dim=-1, keepdim=True)  # Normalize embeddings\n",
    "\n",
    "    # Return the embeddings\n",
    "    return {\n",
    "        \"text_embedding\": text_embeddings.numpy() if text_embeddings is not None else None,\n",
    "        \"image_embedding\": image_embeddings.numpy() if image_embeddings is not None else None\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0effb2-cbd3-4318-8c51-c0313a1c0f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|                                                                                 | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71fbccbbe436481999bdf6fe2b93a8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   1%|▊                                                                        | 1/89 [00:06<08:51,  6.04s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2959ea75624d91a7ef6302c8cc806a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   2%|█▋                                                                       | 2/89 [00:11<08:02,  5.55s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5ea0dd17554f3a9118349ee336bac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   3%|██▍                                                                      | 3/89 [00:16<07:39,  5.34s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a9f542f4db4a24a93fc2c2a6ce8945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   4%|███▎                                                                     | 4/89 [00:21<07:21,  5.20s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4648eca5127845a0bec0144a5770dd9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   6%|████                                                                     | 5/89 [00:26<07:12,  5.15s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9530330b51a467f9cb20eeb6a481944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   7%|████▉                                                                    | 6/89 [00:31<07:03,  5.11s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875f4673c48e409a8c42af5dd57f162d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   8%|█████▋                                                                   | 7/89 [00:36<06:59,  5.11s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f621c39783e8499bae8f72e033fc3fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   9%|██████▌                                                                  | 8/89 [00:41<06:50,  5.07s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6ae4d81b8d44b5a28938c4b2e4062a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  10%|███████▍                                                                 | 9/89 [00:46<06:45,  5.07s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a49f43466841558f94c3dd4a533006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  11%|████████                                                                | 10/89 [00:51<06:38,  5.05s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9e056775174db7932fe401666db9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  12%|████████▉                                                               | 11/89 [00:56<06:30,  5.00s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a40e8747f314366aaa32b042d91acc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  13%|█████████▋                                                              | 12/89 [01:01<06:33,  5.10s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43b0f088a0a4f97a488b0813e236152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  15%|██████████▌                                                             | 13/89 [01:07<06:33,  5.18s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35af6b7617244e39d7484602a1c0764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  16%|███████████▎                                                            | 14/89 [01:12<06:22,  5.10s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5106b751a4b4fa7b16cdf6b8894148b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  17%|████████████▏                                                           | 15/89 [01:17<06:15,  5.07s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba62b6d98bb4a918c314edf935d6823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  18%|████████████▉                                                           | 16/89 [01:22<06:08,  5.05s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74734ee82c79415e99157ec761f3eea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  19%|█████████████▊                                                          | 17/89 [01:27<06:01,  5.02s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ae151d7e974680b6e7e2a6cb949c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  20%|██████████████▌                                                         | 18/89 [01:32<05:56,  5.03s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e7803c0fc04289bc7bb2b16d7e0dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  21%|███████████████▎                                                        | 19/89 [01:37<05:50,  5.01s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93043f802323448a926fa7f086588624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  22%|████████████████▏                                                       | 20/89 [01:42<05:46,  5.01s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3214c7bfa574c65b0e786ea203b126e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  24%|████████████████▉                                                       | 21/89 [01:47<05:45,  5.08s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2a03e1bdb94d6e8e6e05a8910347da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  25%|█████████████████▊                                                      | 22/89 [01:52<05:37,  5.04s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c453143f78b444c8ab2cf7308f341d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  26%|██████████████████▌                                                     | 23/89 [01:57<05:35,  5.08s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68856f6156184681869d9fcca6710f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  27%|███████████████████▍                                                    | 24/89 [02:02<05:36,  5.18s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc6710de14843e5b68bff0720b6d8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  28%|████████████████████▏                                                   | 25/89 [02:07<05:28,  5.14s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cd18c2868b4c7da871f385f8603a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  29%|█████████████████████                                                   | 26/89 [02:13<05:23,  5.14s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd56b4dd00f349cf8a4e10d2003777ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  30%|█████████████████████▊                                                  | 27/89 [02:18<05:16,  5.11s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f29e4dc716743358ac324172556b78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  31%|██████████████████████▋                                                 | 28/89 [02:23<05:15,  5.18s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57e9eaf10564266a5e0a99452e8536a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  33%|███████████████████████▍                                                | 29/89 [02:28<05:08,  5.14s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2443f6c99e4956be881583957397cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  34%|████████████████████████▎                                               | 30/89 [02:33<05:00,  5.10s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf2382fbd5040ac92192b4da257f262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  35%|█████████████████████████                                               | 31/89 [02:38<04:54,  5.08s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7b5d6f178245199cff65f8202ff611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  36%|█████████████████████████▉                                              | 32/89 [02:43<04:48,  5.07s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3a1c76ab5b4ce89e408afd498a3ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  37%|██████████████████████████▋                                             | 33/89 [02:48<04:42,  5.04s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13078af0addc4dbd8a0ebdce9f163b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  38%|███████████████████████████▌                                            | 34/89 [02:53<04:36,  5.03s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efe13ff0c8d4cf2aacbcf2b7e1f4de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  39%|████████████████████████████▎                                           | 35/89 [02:58<04:38,  5.16s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced2adbe629646c085330f209fc565e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  40%|█████████████████████████████                                           | 36/89 [03:04<04:31,  5.13s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32df02c0082e422591f33f5f915dfbae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  42%|█████████████████████████████▉                                          | 37/89 [03:08<04:23,  5.08s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2660077e98f84a4190c1a7b937726177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  43%|██████████████████████████████▋                                         | 38/89 [03:14<04:24,  5.20s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49edabe665d4947a5ced2653b6de0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  44%|███████████████████████████████▌                                        | 39/89 [03:19<04:16,  5.13s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a181895fbb3a4d1cbf2e43a6bb2754f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  45%|████████████████████████████████▎                                       | 40/89 [03:24<04:15,  5.22s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486c718bbf0c4a3394875958a693b203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  46%|█████████████████████████████████▏                                      | 41/89 [03:29<04:08,  5.17s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcd8a8986ba46c39f769f2afa0f14e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  47%|█████████████████████████████████▉                                      | 42/89 [03:34<04:01,  5.13s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a51fa15cd74faf88f01979cb4123f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  48%|██████████████████████████████████▊                                     | 43/89 [03:40<03:56,  5.15s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85543c2608194cb88f2bd4dbefe8d631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  49%|███████████████████████████████████▌                                    | 44/89 [03:45<03:54,  5.21s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964b9857580340dcb4e18b47de3b6925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  51%|████████████████████████████████████▍                                   | 45/89 [03:50<03:51,  5.27s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574a7d0cd52346c88e9c699fb2ed84c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  52%|█████████████████████████████████████▏                                  | 46/89 [03:56<03:49,  5.33s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fb875036714403b24495525efa6ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  53%|██████████████████████████████████████                                  | 47/89 [04:01<03:40,  5.25s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be56b752a3042ecbb2b55da0822bbec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  54%|██████████████████████████████████████▊                                 | 48/89 [04:06<03:33,  5.20s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d610686f854c1b80e8e182d5f9ce03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  55%|███████████████████████████████████████▋                                | 49/89 [04:11<03:26,  5.16s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbc3baae580479f8f8e6edba7aa2f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  56%|████████████████████████████████████████▍                               | 50/89 [04:16<03:20,  5.14s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d1839350dee458e94c8453e84900903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  57%|█████████████████████████████████████████▎                              | 51/89 [04:21<03:17,  5.19s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0f197b88ef4a758ed40906f8ab861a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  58%|██████████████████████████████████████████                              | 52/89 [04:27<03:10,  5.16s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358178878f1549ebad29a7b2647dcf9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  60%|██████████████████████████████████████████▉                             | 53/89 [04:32<03:04,  5.13s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38bc1738bb684774909dc0eee41c45d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  61%|███████████████████████████████████████████▋                            | 54/89 [04:37<02:59,  5.14s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e683188769e8491f8d48908b93a16964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  62%|████████████████████████████████████████████▍                           | 55/89 [04:42<02:54,  5.15s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3106504eaf469ebbeae647b41d8795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  63%|█████████████████████████████████████████████▎                          | 56/89 [04:47<02:49,  5.14s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcf28820423484b9715d61acc77054f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  64%|██████████████████████████████████████████████                          | 57/89 [04:52<02:43,  5.12s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0535f52a01e143b39b92d4a01bf26f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  65%|██████████████████████████████████████████████▉                         | 58/89 [04:57<02:38,  5.12s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385a640b799a4cfb87104f68b51959ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  66%|███████████████████████████████████████████████▋                        | 59/89 [05:03<02:34,  5.16s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ba31d6f34849688e3f0d047469a761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  67%|████████████████████████████████████████████████▌                       | 60/89 [05:08<02:29,  5.14s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f299763887448ba9088d4644628f47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  69%|█████████████████████████████████████████████████▎                      | 61/89 [05:13<02:23,  5.14s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a74a5fe80ef41fe9fefcb85b7dcde1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  70%|██████████████████████████████████████████████████▏                     | 62/89 [05:18<02:18,  5.12s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f08afa34244155baf4ded09d47cab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  71%|██████████████████████████████████████████████████▉                     | 63/89 [05:23<02:12,  5.11s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f75c18d1944bf38199b25b8b088eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  72%|███████████████████████████████████████████████████▊                    | 64/89 [05:28<02:07,  5.08s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define directories for text, tables, and images\n",
    "text_dir = \"../data/data/text\"\n",
    "table_dir = \"../data/data/tables\"\n",
    "image_dir = \"../data/data/images\"\n",
    "\n",
    "# Collect file paths for each type\n",
    "text_files = [os.path.join(text_dir, f) for f in os.listdir(text_dir) if f.endswith(\".txt\")]\n",
    "table_files = [os.path.join(table_dir, f) for f in os.listdir(table_dir) if f.endswith(\".txt\")]\n",
    "image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(\".png\")]\n",
    "\n",
    "# Create `items` list\n",
    "items = []\n",
    "\n",
    "# Add text files\n",
    "for text_file in text_files:\n",
    "    with open(text_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        text_content = f.read()\n",
    "    items.append({\"type\": \"text\", \"text\": text_content})\n",
    "\n",
    "# Add table files\n",
    "for table_file in table_files:\n",
    "    with open(table_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        table_content = f.read()\n",
    "    items.append({\"type\": \"table\", \"text\": table_content})\n",
    "\n",
    "# Add image files\n",
    "for image_file in image_files:\n",
    "    items.append({\"type\": \"image\", \"image\": image_file})\n",
    "\n",
    "\n",
    "# Set embedding vector dimension\n",
    "embedding_vector_dimension = 384\n",
    "\n",
    "# Count the number of each type of item\n",
    "item_counts = {\n",
    "    'text': sum(1 for item in items if item['type'] == 'text'),\n",
    "    'table': sum(1 for item in items if item['type'] == 'table'),\n",
    "    'image': sum(1 for item in items if item['type'] == 'image'),\n",
    "}\n",
    "\n",
    "# Initialize counters\n",
    "counters = dict.fromkeys(item_counts.keys(), 0)\n",
    "\n",
    "# Generate embeddings for all items\n",
    "valid_embeddings = []\n",
    "\n",
    "with tqdm(total=len(items), desc=\"Generating embeddings\") as pbar:\n",
    "    for item in items:\n",
    "        item_type = item['type']\n",
    "        counters[item_type] += 1\n",
    "\n",
    "        try:\n",
    "            if item_type in ['text', 'table']:\n",
    "                # Validate and process text or table content\n",
    "                if not item.get('text'):\n",
    "                    raise ValueError(\"Missing text data.\")\n",
    "                embedding = generate_multimodal_embeddings(\n",
    "                    prompt=item['text'], \n",
    "                    output_embedding_length=embedding_vector_dimension\n",
    "                )[\"text_embedding\"]\n",
    "            elif item_type == 'image':\n",
    "                # Validate and process images\n",
    "                if not os.path.exists(item['image']):\n",
    "                    raise FileNotFoundError(f\"Image file not found: {item['image']}\")\n",
    "                embedding = generate_multimodal_embeddings(\n",
    "                    image_path=item['image'], \n",
    "                    output_embedding_length=embedding_vector_dimension\n",
    "                )[\"image_embedding\"]\n",
    "            else:\n",
    "                embedding = None\n",
    "\n",
    "            # Add valid embedding to the list\n",
    "            if embedding is not None:\n",
    "                valid_embeddings.append(embedding)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process item {item}: {e}\")\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "# Ensure valid_embeddings is not empty\n",
    "if not valid_embeddings:\n",
    "    raise ValueError(\"No valid embeddings to add to FAISS. Check your input data.\")\n",
    "\n",
    "# Convert to NumPy array\n",
    "all_embeddings = np.array(valid_embeddings, dtype=np.float32)\n",
    "if len(all_embeddings.shape) == 1:\n",
    "    all_embeddings = all_embeddings.reshape(1, -1)  # Ensure 2D shape\n",
    "\n",
    "# Create FAISS Index\n",
    "index = faiss.IndexFlatL2(embedding_vector_dimension)\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(all_embeddings)\n",
    "\n",
    "print(f\"FAISS index built with {index.ntotal} embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3b2af30-7acc-4ee0-8f53-de20c59ff189",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# All the embeddings\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membedding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m items])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create FAISS Index\u001b[39;00m\n\u001b[0;32m      5\u001b[0m index \u001b[38;5;241m=\u001b[39m faiss\u001b[38;5;241m.\u001b[39mIndexFlatL2(embedding_vector_dimension)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'embedding'"
     ]
    }
   ],
   "source": [
    "# All the embeddings\n",
    "all_embeddings = np.array([item['embedding'] for item in items])\n",
    "\n",
    "# Create FAISS Index\n",
    "index = faiss.IndexFlatL2(embedding_vector_dimension)\n",
    "\n",
    "# Clear any pre-existing index\n",
    "index.reset()\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(np.array(all_embeddings, dtype=np.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
